<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex"><meta name="built-on" content="2024-08-08T20:49:55.865064932"><title>Local AI | Manjaro Guide</title><script type="application/json" id="virtual-toc-data">[{"id":"introduction","level":0,"title":"Introduction","anchor":"#introduction"},{"id":"lmstudio","level":0,"title":"LMStudio","anchor":"#lmstudio"},{"id":"jan-ai","level":0,"title":"Jan AI","anchor":"#jan-ai"},{"id":"ollama","level":0,"title":"Ollama","anchor":"#ollama"},{"id":"update","level":0,"title":"Update","anchor":"#update"},{"id":"installing-specific-versions","level":0,"title":"Installing specific versions","anchor":"#installing-specific-versions"},{"id":"viewing-logs","level":0,"title":"Viewing logs","anchor":"#viewing-logs"},{"id":"uninstall","level":0,"title":"Uninstall","anchor":"#uninstall"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b408/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Local AI | Manjaro Guide"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="Manjaro Guide Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/local-ai.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Local AI | Manjaro Guide"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/local-ai.html#webpage",
    "url": "writerside-documentation/local-ai.html",
    "name": "Local AI | Manjaro Guide",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/#website",
    "url": "writerside-documentation/",
    "name": "Manjaro Guide Help"
}</script><!-- End Schema.org --></head><body data-id="local-ai" data-main-title="Local AI" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs=""><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>Manjaro Guide  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="local-ai" id="local-ai.md">Local AI</h1><section class="chapter"><h2 id="introduction" data-toc="introduction">Introduction</h2><p id="-3fo6rm_11">Local AI is a term used to describe the use of AI models on a local device, such as a smartphone or a computer. This is in contrast to cloud-based AI, where the AI model is hosted on a remote server and accessed over the internet. Local AI has several advantages, including improved privacy and reduced latency. However, it also has some limitations, such as limited processing power and storage space.</p><section class="chapter"><h3 id="install-amd-drivers-rocm" data-toc="install-amd-drivers-rocm">Install AMD drivers (ROCm)</h3><div class="code-block" data-lang="bash">
sudo pacman -S --needed rocm-hip-sdk rocm-opencl-sdk rocm-hip-runtime hip-runtime-amd miopen-hip rocm-opencl-runtime
</div></section><section class="chapter"><h3 id="opencl-image-support" data-toc="opencl-image-support">OpenCL Image support</h3><p id="-3fo6rm_15">The latest ROCm versions now includes OpenCL Image Support used by GPGPU accelerated software such as Darktable. ROCm with the AMDGPU open source graphics driver are all that is required. AMDGPU PRO is not required.</p><div class="code-block" data-lang="bash">
‚ùØ /opt/rocm/bin/clinfo | grep -i &quot;image support&quot;
  Image support:				 Yes
</div></section></section><section class="chapter"><h2 id="lmstudio" data-toc="lmstudio">LMStudio</h2><p id="-3fo6rm_17">LM Studio is a desktop application for running local LLMs on your computer. Install from AUR:</p><div class="code-block" data-lang="bash">
yay -S --needed lmstudio-appimage
</div></section><section class="chapter"><h2 id="jan-ai" data-toc="jan-ai">Jan AI</h2><p id="-3fo6rm_19">Jan is a ChatGPT-alternative that runs 100% offline on your Desktop. Our goal is to make it easy for a person to download and run LLMs and use AI with full control and privacy. Install from AUR:</p><div class="code-block" data-lang="bash">
yay -S --needed jan-bin
</div></section><section class="chapter"><h2 id="ollama" data-toc="ollama">Ollama</h2><p id="-3fo6rm_21">Ollama is a free and open-source AI assistant that runs locally on your device. It can perform a wide range of tasks, such as answering questions, setting reminders, and playing music.</p><section class="chapter"><h3 id="install-from-an-official-repository" data-toc="install-from-an-official-repository">Install from an official repository:</h3><div class="code-block" data-lang="bash">
sudo pacman -S --needed ollama
sudo systemctl enable --now ollama.service
</div></section><section class="chapter"><h3 id="install-from-script" data-toc="install-from-script">Install from script:</h3><div class="code-block" data-lang="bash">
curl -fsSL https://ollama.com/install.sh | sh
</div></section><section class="chapter"><h3 id="install-from-source" data-toc="install-from-source">Install from source:</h3><p id="-3fo6rm_29">Ollama is distributed as a self-contained binary. Download it to a directory in your PATH:</p><div class="code-block" data-lang="bash">
sudo curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/bin/ollama
sudo chmod +x /usr/bin/ollama
</div></section><section class="chapter"><h3 id="adding-ollama-as-a-startup-service-recommended" data-toc="adding-ollama-as-a-startup-service-recommended">Adding Ollama as a startup service (recommended)</h3><p id="-3fo6rm_31">Create a user for Ollama:</p><div class="code-block" data-lang="bash">
sudo useradd -r -s /bin/false -m -d /usr/share/ollama ollama
</div><p id="-3fo6rm_33">Create a service file in <code class="code" id="-3fo6rm_37">/etc/systemd/system/ollama.service</code>:</p><div class="code-block" data-lang="ini">
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3

[Install]
WantedBy=default.target
</div><p id="-3fo6rm_35">Then start the service:</p><div class="code-block" data-lang="bash">
sudo systemctl daemon-reload
sudo systemctl enable --now ollama
</div></section><section class="chapter"><h3 id="amd-radeon-gpu-support" data-toc="amd-radeon-gpu-support">AMD Radeon GPU support</h3><p id="-3fo6rm_38">While AMD has contributed the <code class="code" id="-3fo6rm_39">amdgpu</code> driver upstream to the official linux kernel source, the version is older and may not support all ROCm features. We recommend you install the latest driver from <a href="https://www.amd.com/en/support/linux-drivers" id="-3fo6rm_40" data-external="true" rel="noopener noreferrer">AMD Official Website</a> for best support of your Radeon GPU.</p></section></section><section class="chapter"><h2 id="update" data-toc="update">Update</h2><p id="-3fo6rm_41">Update ollama by running the install script again:</p><div class="code-block" data-lang="bash">
curl -fsSL https://ollama.com/install.sh | sh
</div><p id="-3fo6rm_43">Or by downloading the ollama binary:</p><div class="code-block" data-lang="bash">
sudo curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/bin/ollama
sudo chmod +x /usr/bin/ollama
</div></section><section class="chapter"><h2 id="installing-specific-versions" data-toc="installing-specific-versions">Installing specific versions</h2><p id="-3fo6rm_45">Use <code class="code" id="-3fo6rm_48">OLLAMA_VERSION</code> environment variable with the install script to install a specific version of Ollama, including pre-releases. You can find the version numbers in the <a href="https://github.com/ollama/ollama/releases" id="-3fo6rm_49" data-external="true" rel="noopener noreferrer">releases page</a>.</p><p id="-3fo6rm_46">For example:</p><div class="code-block" data-lang="none">
curl -fsSL https://ollama.com/install.sh | OLLAMA_VERSION=0.1.32 sh
</div></section><section class="chapter"><h2 id="viewing-logs" data-toc="viewing-logs">Viewing logs</h2><p id="-3fo6rm_50">To view logs of Ollama running as a startup service, run:</p><div class="code-block" data-lang="bash">
journalctl -e -u ollama
</div></section><section class="chapter"><h2 id="uninstall" data-toc="uninstall">Uninstall</h2><p id="-3fo6rm_52">Remove the ollama service:</p><div class="code-block" data-lang="bash">
sudo systemctl stop ollama
sudo systemctl disable ollama
sudo rm /etc/systemd/system/ollama.service
</div><p id="-3fo6rm_54">Remove the ollama binary from your bin directory (either <code class="code" id="-3fo6rm_58">/usr/local/bin</code>, <code class="code" id="-3fo6rm_59">/usr/bin</code>, or <code class="code" id="-3fo6rm_60">/bin</code>):</p><div class="code-block" data-lang="bash">
sudo rm $(which ollama)
</div><p id="-3fo6rm_56">Remove the downloaded models and Ollama service user and group:</p><div class="code-block" data-lang="bash">
sudo rm -r /usr/share/ollama
sudo userdel ollama
sudo groupdel ollama
</div></section><div class="last-modified">Last modified: 08 August 2024</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="solutions-archive.html" class="navigation-links__prev">Solutions Archive</a><a href="references.html" class="navigation-links__next">References</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b408/app.js"></script></body></html>